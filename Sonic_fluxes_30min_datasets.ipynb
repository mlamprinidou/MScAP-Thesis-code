{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc9ff43",
   "metadata": {},
   "source": [
    "### What this script does (short)\n",
    "\n",
    "- Reads all .dat high-frequency sonic files in a given day’s folder.\n",
    "\n",
    "- Splits data into 30-minute chunks (for 20 Hz → 30 min = 36 000 samples).\n",
    "\n",
    "- Computes turbulent covariances/fluxes per chunk: wT_Flux, wrhoqv_Flux, wrhoco2_Flux, and momentum fluxes uw, vw, uv.\n",
    "\n",
    "- Averages of temperature (raw & corrected, in K), H₂O/CO₂ density, and wind components (Ux, Uy, Uz).\n",
    "\n",
    "- Derives sensible heat flux (SHF) and latent heat flux (LHF).\n",
    "\n",
    "- Saves flux_data_30min.csv in the same day folder.\n",
    "\n",
    "Edit before running:\n",
    "  \n",
    "  1) Base folder for the specific day you want to process: e.g. data_dir = r\"C:\\path\\to\\your\\Sonic\\2024-05\\2024-05-26\"\n",
    "\n",
    "  2) (Optional) Sampling-rate assumption for 30-min chunks:\n",
    "     e.g. At 20 Hz → 30 min = 20 * 60 * 30 = 36000 samples\n",
    "     \n",
    "       If your sampling rate differs, update the step size below:\n",
    "       \n",
    "       for i in range(0, len(data), 36000):\n",
    "\n",
    "\n",
    "Everything else can remain as-is. The script will discover all .dat files in data_dir, compute the 30-min statistics/fluxes, and create at that same folder\\flux_data_30min.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cp = 1005  # Specific heat capacity of dry air at constant pressure (J/kg/K)\n",
    "g = 9.81   # Acceleration due to gravity (m/s^2)\n",
    "rho=1.2 #air density\n",
    "Lv = 2.5e6  # Latent heat of vaporization in J/kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc753011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Base folder for the specific day you want to process\n",
    "# ⚠️ Edit this to your local path (year/month/day).\n",
    "# Example: data_dir = r\"D:\\Thesis\\data\\Sonic\\2024-05\\2024-05-26\"\n",
    "data_dir = r\"C:\\path\\to\\your\\Sonic\\2024-05\\2024-05-26\"\n",
    "\n",
    "# 2) (Optional) Sampling-rate assumption for 30-min chunks:\n",
    "#    At 20 Hz → 30 min = 20 * 60 * 30 = 36000 samples\n",
    "#    If your sampling rate differs, update the step size below.\n",
    "# for i in range(0, len(data), 36000):\n",
    "\n",
    "\n",
    "# Initialize lists to store 30-minute fluxes and corresponding timestamps\n",
    "timestamps_30min = []\n",
    "wT_fluxes_30min = []\n",
    "wrhoqv_fluxes_30min = []\n",
    "wrhoco2_fluxes_30min = []\n",
    "average_temperatures_30min = []\n",
    "average_temperatures_corr_30min = []\n",
    "average_h2o_density_30min = []\n",
    "average_co2_density_30min = []\n",
    "average_wind_ux_30min = []\n",
    "average_wind_uy_30min = []\n",
    "average_wind_uz_30min = []\n",
    "uw_flux_30min = []\n",
    "vw_flux_30min = []\n",
    "uv_flux_30min = []\n",
    "\n",
    "# Loop through all .dat files in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.dat'):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        \n",
    "        # Load data from the .dat file, skipping the first row\n",
    "        data = pd.read_csv(file_path, skiprows=1, delimiter=',', encoding='latin1', low_memory=False)\n",
    "        \n",
    "        # Drop any rows with missing values\n",
    "        data.dropna(inplace=True)\n",
    "        \n",
    "        # Convert the timestamp to datetime format\n",
    "        data['TIMESTAMP'] = pd.to_datetime(data['TIMESTAMP'], errors='coerce')\n",
    "        data['Ux'] = pd.to_numeric(data['Ux'], errors='coerce')\n",
    "        data['Uy'] = pd.to_numeric(data['Uy'], errors='coerce')\n",
    "        data['Uz'] = pd.to_numeric(data['Uz'], errors='coerce')\n",
    "        data['T_SONIC'] = pd.to_numeric(data['T_SONIC'], errors='coerce')\n",
    "        data['T_SONIC_corr'] = pd.to_numeric(data['T_SONIC_corr'], errors='coerce')\n",
    "        data['H2O_density'] = pd.to_numeric(data['H2O_density'], errors='coerce')\n",
    "        data['CO2_density'] = pd.to_numeric(data['CO2_density'], errors='coerce')\n",
    "\n",
    "        # Loop through each 30-minute chunk in the file (36000 samples for 30 minutes at 20 Hz)\n",
    "        for i in range(0, len(data), 36000):\n",
    "            thirty_minute_data = data.iloc[i:i+36000]  # Get data for 30 minutes\n",
    "            \n",
    "            if not thirty_minute_data.empty:\n",
    "                # Calculate 30-minute means\n",
    "                mean_wind_ux = thirty_minute_data['Ux'].mean()\n",
    "                mean_wind_uy = thirty_minute_data['Uy'].mean()\n",
    "                mean_wind_uz = thirty_minute_data['Uz'].mean()\n",
    "                mean_T_sonic = thirty_minute_data['T_SONIC'].mean()\n",
    "                mean_T_sonic_corr = thirty_minute_data['T_SONIC_corr'].mean()\n",
    "                mean_h2o_density = thirty_minute_data['H2O_density'].mean()\n",
    "                mean_co2_density = thirty_minute_data['CO2_density'].mean()\n",
    "\n",
    "                # Calculate perturbations for wind components\n",
    "                u_prime = thirty_minute_data['Ux'] - mean_wind_ux\n",
    "                v_prime = thirty_minute_data['Uy'] - mean_wind_uy\n",
    "                w_prime = thirty_minute_data['Uz'] - mean_wind_uz\n",
    "                \n",
    "                # Calculate momentum fluxes\n",
    "                uw_flux = u_prime * w_prime\n",
    "                vw_flux = v_prime * w_prime\n",
    "                uv_flux = u_prime * v_prime\n",
    "                \n",
    "                t_sonic_prime = thirty_minute_data['T_SONIC_corr'] - mean_T_sonic_corr\n",
    "                \n",
    "                # Calculate wT flux (w'T' flux)\n",
    "                wT_flux = (w_prime * (t_sonic_prime + 273.15)).mean()\n",
    "                \n",
    "                # w'qv'flux\n",
    "                rhoqv_prime = thirty_minute_data['H2O_density'] - mean_h2o_density\n",
    "                wrhoqv_flux = (w_prime * rhoqv_prime).mean()\n",
    "                \n",
    "                # rhoCo2'\n",
    "                rhoco2_prime = thirty_minute_data['CO2_density'] - mean_co2_density\n",
    "                # w'rhoco2'\n",
    "                wrhoco2_flux = (rhoco2_prime * w_prime).mean()\n",
    "        \n",
    "                # Store data in lists\n",
    "                timestamps_30min.append(thirty_minute_data['TIMESTAMP'].iloc[0].floor('30T'))\n",
    "                wT_fluxes_30min.append(wT_flux)\n",
    "                wrhoqv_fluxes_30min.append(wrhoqv_flux)\n",
    "                wrhoco2_fluxes_30min.append(wrhoco2_flux)\n",
    "                average_temperatures_30min.append(mean_T_sonic + 273.15)\n",
    "                average_temperatures_corr_30min.append(mean_T_sonic_corr + 273.15)\n",
    "                average_h2o_density_30min.append(mean_h2o_density)\n",
    "                average_co2_density_30min.append(mean_co2_density)\n",
    "                average_wind_ux_30min.append(mean_wind_ux)\n",
    "                average_wind_uy_30min.append(mean_wind_uy)\n",
    "                average_wind_uz_30min.append(mean_wind_uz)\n",
    "                uw_flux_30min.append(uw_flux.mean())\n",
    "                vw_flux_30min.append(vw_flux.mean())\n",
    "                uv_flux_30min.append(uv_flux.mean())\n",
    "\n",
    "# Create DataFrame for the collected data\n",
    "flux_data_30min = pd.DataFrame({\n",
    "    'TIMESTAMP': timestamps_30min,\n",
    "    'wT_Flux': wT_fluxes_30min,\n",
    "    'wrhoqv_Flux': wrhoqv_fluxes_30min,\n",
    "    'Average_Temperature': average_temperatures_30min,\n",
    "    'Average_Temperature_Corr': average_temperatures_corr_30min,\n",
    "    'Average_H2O_Density': average_h2o_density_30min,\n",
    "    'Average_CO2_Density': average_co2_density_30min,\n",
    "    'wrhoCO2_Flux': wrhoco2_fluxes_30min,\n",
    "    'Average_Wind_Ux': average_wind_ux_30min,\n",
    "    'Average_Wind_Uy': average_wind_uy_30min,\n",
    "    'Average_Wind_Uz': average_wind_uz_30min,\n",
    "    'uw_flux': uw_flux_30min,\n",
    "    'vw_flux': vw_flux_30min,\n",
    "    'uv_flux': uv_flux_30min\n",
    "})\n",
    "\n",
    "print(flux_data_30min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cfc19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensible heat flux (SHF)\n",
    "flux_data_30min['SHF'] = flux_data_30min['wT_Flux'] * rho* Cp\n",
    "\n",
    "# Calculate latent heat flux (LHF)\n",
    "flux_data_30min['wqv_Flux'] = flux_data_30min['wrhoqv_Flux'] / rho\n",
    "flux_data_30min['LHF'] = flux_data_30min['wqv_Flux'] * rho * Lv / 1000\n",
    "\n",
    "print(flux_data_30min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e4e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path for the CSV file\n",
    "output_file_path = os.path.join(data_dir, 'flux_data_30min.csv')\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "flux_data_30min.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data successfully saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
