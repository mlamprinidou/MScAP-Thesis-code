{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9673a1",
   "metadata": {},
   "source": [
    "### What this script does\n",
    "\n",
    "- Scans a folder of NetCDF (*.NC) files, inventories variables (name/dims/shape/dtype/units), and writes a single PDF report.\n",
    "\n",
    "- (Optional) For a month folder, loads daily IWV/LWP files, converts time, resamples to 10-min means, saves iwv_lwp_10min_avg.csv per day.\n",
    "- Loops day-folders under a month, reads IWV (*.iwv.nc) and LWP (*.lwp.nc), converts Cloudnet “seconds since 2001-01-01” to datetimes, applies an offset using Min_LWP so that minima align to −5 g/m², merges, resamples to 10-minute means, writes iwv_lwp_10min_avg.csv per day.\n",
    "\n",
    "- Loops day-folders again, reads temperature profiles (*.tpc.nc), converts time, computes 10-minute mean vertical temperature profiles, saves vertical_temperature_profiles_10min_avg.parquet per day.\n",
    "\n",
    "- Opens a .TPB.NC file and plots time-sequenced temperature and dry static energy vertical profiles (full column and 0–1 km), saving PNGs per time.\n",
    "\n",
    "- Walks daily folders, opens .HPC.NC (Relative/Absolute Humidity profiles), converts Cloudnet time to datetimes, computes 10-min mean RH/AH profiles, saves as Parquet.\n",
    "\n",
    "- Makes quicklook plots (first profile) and can render a GIF of RH profiles for the whole day, plus hourly overlays.\n",
    "\n",
    "- (Optional) Flattens HPC profiles to a tidy DataFrame (Time, Altitude, RH).\n",
    "\n",
    "- Picks the MET file (*.MET.NC) and reads surface pressure (Surf_P), surface temperature (Surf_T) and time.\n",
    "\n",
    "- Picks the TPC file (*.TPC.NC) and reads temperature profiles and altitude, computes saturation vapor pressure profiles es.\n",
    "\n",
    "- Flattens HPC (RH) + TPC to tidy tables, merges (Time, Altitude) to get RH + Temperature + es.\n",
    "\n",
    "- Merges in surface pressure/temperature and computes a pressure profile vs altitude; then computes specific humidity qv profile using ev = RH * es / 100 and your calculate_specific_humidity.\n",
    "\n",
    "- Plots qv(z) for each time and several quicklook plots (El/Azi angles, LWP, rain flag, temperature curtain).\n",
    "\n",
    "\n",
    "\n",
    "#### Edit these lines:\n",
    "\n",
    "- Input folder (inventory PDF): folder_path = Path('path/to/folder/Microwave_radiometer/NC/files') <-- e.g., Path('/data/Microwave_radiometer/2024-05/2024-05-01')\n",
    "- (Optional) Month folder for IWV/LWP (uncomment that block first): base_folder_path = Path('path/to/Microwave_radiometer/month-folder') <-- e.g., Path('/data/Microwave_radiometer/2024-06')\n",
    "\n",
    "\n",
    "- (Optional preview) Single parquet path: parquet_file_path = Path('/path/to/any/day/vertical_temperature_profiles_10min_avg.parquet')\n",
    "\n",
    "- main_folder_path = Path('/path/to/Microwave_radiometer/2024-06')\n",
    "\n",
    "- file_path_2 = Path('/path/to/Microwave_radiometer/2024-05/2024-05-03')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512559f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install netCDF4\n",
    "pip install reportlab\n",
    "pip install imageio[ffmpeg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5dead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import imageio\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e1d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "C_p = 1005  # Specific heat capacity of dry air at constant pressure (J/kg/K)\n",
    "g = 9.81    # Gravitational acceleration (m/s^2)\n",
    "Ttrip = 273.16  # Triple point temperature in Kelvin\n",
    "Rd=287.04\n",
    "Rv=461.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time from seconds since 1.1.2001, 00:00:00 to datetime\n",
    "def convert_time(base_time, time_array):\n",
    "    return [base_time + timedelta(seconds=int(t)) for t in time_array]\n",
    "# Function to calculate saturation vapor pressure (es) from temperature (T)\n",
    "def calculate_saturation_vapor_pressure(T):\n",
    "    es = 610.78 * np.exp(17.2694 * (T - Ttrip) / (T - 35.86))\n",
    "    return es\n",
    "# Function to calculate pressure at altitude z given surface pressure and temperature\n",
    "def calculate_pressure(P_surf, z, T):\n",
    "    return P_surf * np.exp(-g * z / (Rd * T))\n",
    "# Function to calculate specific humidity (qv) from vapor pressure (ev) and atmospheric pressure (p)\n",
    "def calculate_specific_humidity(ev, p):\n",
    "    return ev * 1000 / (p*100 + (((Rv / Rd) - 1) * (p*100 - ev)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22c15b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Edit this line before runing!!\n",
    "folder_path = Path('path/to/folder/Microwave_radiometer/NC/files')   # e.g., Path('/data/Microwave_radiometer/2024-05/2024-05-01')\n",
    "\n",
    "# Get a list of all .NC files in the folder\n",
    "nc_files = [f for f in os.listdir(folder_path) if f.endswith('.NC')]\n",
    "\n",
    "# Dictionary to store the datasets\n",
    "datasets = {}\n",
    "\n",
    "\n",
    "# Dictionary to store the datasets\n",
    "datasets = {}\n",
    "\n",
    "# Loop through each file and open it\n",
    "for file_name in nc_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    dataset = nc.Dataset(file_path, mode='r')\n",
    "    datasets[file_name] = dataset\n",
    "\n",
    "# Create a PDF file\n",
    "pdf_path = 'NC_Variables_Report.pdf'\n",
    "doc = SimpleDocTemplate(pdf_path, pagesize=letter)\n",
    "story = []\n",
    "\n",
    "# Define styles\n",
    "styles = getSampleStyleSheet()\n",
    "title_style = styles['Title']\n",
    "normal_style = styles['Normal']\n",
    "\n",
    "for file_name, dataset in datasets.items():\n",
    "    # Add file name as title\n",
    "    story.append(Paragraph(f'File: {file_name}', title_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Add variable information\n",
    "    for var_name in dataset.variables:\n",
    "        var_info = f\"Variable Name: {var_name}\\n\"\n",
    "        var_info += f\"   Dimensions: {dataset.variables[var_name].dimensions}\\n\"\n",
    "        var_info += f\"   Shape: {dataset.variables[var_name].shape}\\n\"\n",
    "        var_info += f\"   Data Type: {dataset.variables[var_name].dtype}\\n\"\n",
    "        var_info += f\"   Units: {dataset.variables[var_name].units if 'units' in dataset.variables[var_name].ncattrs() else 'N/A'}\\n\"\n",
    "        var_info += \"\\n\"\n",
    "        \n",
    "        story.append(Paragraph(var_info, normal_style))\n",
    "    \n",
    "    # Add a spacer between files\n",
    "    story.append(Spacer(1, 24))\n",
    "\n",
    "# Build the PDF\n",
    "doc.build(story)\n",
    "\n",
    "# Close all datasets\n",
    "for dataset in datasets.values():\n",
    "    dataset.close()\n",
    "\n",
    "print(f\"PDF saved to {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f76e3",
   "metadata": {},
   "source": [
    "### LWP, IWV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d91a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Edit before running!1\n",
    "# Define the base folder path\n",
    "base_folder_path = Path('path/to/Microwave_radiometer/month-folder') #<-- e.g., Path('/data/Microwave_radiometer/2024-06')\n",
    "\n",
    "# Function to convert time from seconds since a base date to datetime\n",
    "def convert_time(base_time, time_array):\n",
    "    return [base_time + dt.timedelta(seconds=int(t)) for t in time_array]\n",
    "\n",
    "# Process each day's folder\n",
    "for day_folder in os.listdir(base_folder_path):\n",
    "    day_folder_path = os.path.join(base_folder_path, day_folder)\n",
    "    if not os.path.isdir(day_folder_path):\n",
    "        continue\n",
    "\n",
    "    # Find the .IWV.NC and .LWP.NC files\n",
    "    iwv_file = next((f for f in os.listdir(day_folder_path) if f.lower().endswith('.iwv.nc')), None)\n",
    "    lwp_file = next((f for f in os.listdir(day_folder_path) if f.lower().endswith('.lwp.nc')), None)\n",
    "\n",
    "    if iwv_file is None or lwp_file is None:\n",
    "        print(f\"Missing files in {day_folder_path}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    iwv_file_path = os.path.join(day_folder_path, iwv_file)\n",
    "    lwp_file_path = os.path.join(day_folder_path, lwp_file)\n",
    "\n",
    "    # Initialize variables\n",
    "    time_iwv = None\n",
    "    iwv_values = None\n",
    "    time_lwp = None\n",
    "    lwp_values = None\n",
    "\n",
    "    # Extract IWV data\n",
    "    try:\n",
    "        with nc.Dataset(iwv_file_path, 'r') as iwv_dataset:\n",
    "            time_iwv = iwv_dataset.variables['time'][:]\n",
    "            iwv_values = iwv_dataset.variables['IWV'][:]\n",
    "            # Print IWV units and other attributes\n",
    "            #print(\"\\nIWV Attributes:\")\n",
    "            #for attr_name in iwv_dataset.variables['IWV'].ncattrs():\n",
    "             #   print(f\"    {attr_name}: {getattr(iwv_dataset.variables['IWV'], attr_name)}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {iwv_file_path}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {iwv_file_path}: {e}\")\n",
    "\n",
    "    # Extract LWP data\n",
    "    try:\n",
    "        with nc.Dataset(lwp_file_path, 'r') as lwp_dataset:\n",
    "            time_lwp = lwp_dataset.variables['time'][:]\n",
    "            lwp_values = lwp_dataset.variables['LWP'][:]\n",
    "            # Print LWP units and other attributes\n",
    "          #  print(\"\\nLWP Attributes:\")\n",
    "           # for attr_name in lwp_dataset.variables['LWP'].ncattrs():\n",
    "            #    print(f\"    {attr_name}: {getattr(lwp_dataset.variables['LWP'], attr_name)}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {lwp_file_path}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {lwp_file_path}: {e}\")\n",
    "\n",
    "    # Convert time variables to datetime\n",
    "    base_time = dt.datetime(2001, 1, 1, 0, 0, 0)\n",
    "    if time_iwv is not None:\n",
    "        times_iwv_converted = convert_time(base_time, time_iwv)\n",
    "    if time_lwp is not None:\n",
    "        times_lwp_converted = convert_time(base_time, time_lwp)\n",
    "\n",
    "    # Create dataframes\n",
    "    df_iwv = pd.DataFrame({'TIMESTAMP': times_iwv_converted, 'IWV': iwv_values})\n",
    "    df_lwp = pd.DataFrame({'TIMESTAMP': times_lwp_converted, 'LWP': lwp_values})\n",
    "\n",
    "    # Merge dataframes on time\n",
    "    df_combined_iwv_lwp = pd.merge(df_iwv, df_lwp, on='TIMESTAMP', how='outer')\n",
    "\n",
    "    # Sort by time\n",
    "    df_combined_iwv_lwp.sort_values(by='TIMESTAMP', inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    df_combined_iwv_lwp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Set the 'Time' column as the index\n",
    "    df_combined_iwv_lwp.set_index('TIMESTAMP', inplace=True)\n",
    "\n",
    "    # Resample the data in 10-minute intervals and calculate the mean\n",
    "    df_combined_iwv_lwp_10min_avg = df_combined_iwv_lwp.resample('10T').mean()\n",
    "\n",
    "    # Reset the index to turn 'Time' back into a column\n",
    "    df_combined_iwv_lwp_10min_avg.reset_index(inplace=True)\n",
    "\n",
    "    # Define the path to save the CSV file\n",
    "    csv_file_path = os.path.join(day_folder_path, 'iwv_lwp_10min_avg.csv')\n",
    "\n",
    "    # Save the dataframe to a CSV file\n",
    "    df_combined_iwv_lwp_10min_avg.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    print(f\"10-minute average IWV and LWP data saved successfully to '{csv_file_path}'\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9f95f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Edit before running!1\n",
    "# Define the base folder path\n",
    "base_folder_path = Path('path/to/Microwave_radiometer/month-folder') #<-- e.g., Path('/data/Microwave_radiometer/2024-03')\n",
    "\n",
    "# Function to convert time from seconds since a base date to datetime\n",
    "def convert_time(base_time, time_array):\n",
    "    return [base_time + dt.timedelta(seconds=int(t)) for t in time_array]\n",
    "\n",
    "# Function to calculate offset\n",
    "def calculate_offset(min_lwp_mwr):\n",
    "    if min_lwp_mwr != -5:\n",
    "        return min_lwp_mwr - (-5)  # Compute the difference from -5\n",
    "    return 0  # Default offset when Min_LWP_MWR is -5\n",
    "\n",
    "# Process each day's folder\n",
    "for day_folder in os.listdir(base_folder_path):\n",
    "    day_folder_path = os.path.join(base_folder_path, day_folder)\n",
    "    if not os.path.isdir(day_folder_path):\n",
    "        continue\n",
    "\n",
    "    # Find the .IWV.NC and .LWP.NC files\n",
    "    iwv_file = next((f for f in os.listdir(day_folder_path) if f.lower().endswith('.iwv.nc')), None)\n",
    "    lwp_file = next((f for f in os.listdir(day_folder_path) if f.lower().endswith('.lwp.nc')), None)\n",
    "\n",
    "    if iwv_file is None or lwp_file is None:\n",
    "        print(f\"Missing files in {day_folder_path}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    iwv_file_path = os.path.join(day_folder_path, iwv_file)\n",
    "    lwp_file_path = os.path.join(day_folder_path, lwp_file)\n",
    "\n",
    "    # Initialize variables\n",
    "    time_iwv = None\n",
    "    iwv_values = None\n",
    "    time_lwp = None\n",
    "    lwp_values = None\n",
    "    min_lwp = None\n",
    "\n",
    "    # Extract IWV data\n",
    "    try:\n",
    "        with nc.Dataset(iwv_file_path, 'r') as iwv_dataset:\n",
    "            time_iwv = iwv_dataset.variables['time'][:]\n",
    "            iwv_values = iwv_dataset.variables['IWV'][:]\n",
    "            # Print IWV units and other attributes\n",
    "            print(\"\\nIWV Attributes:\")\n",
    "            for attr_name in iwv_dataset.variables['IWV'].ncattrs():\n",
    "                print(f\"    {attr_name}: {getattr(iwv_dataset.variables['IWV'], attr_name)}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {iwv_file_path}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {iwv_file_path}: {e}\")\n",
    "\n",
    "    # Extract LWP data\n",
    "    try:\n",
    "        with nc.Dataset(lwp_file_path, 'r') as lwp_dataset:\n",
    "            time_lwp = lwp_dataset.variables['time'][:]\n",
    "            lwp_values = lwp_dataset.variables['LWP'][:]\n",
    "            min_lwp = lwp_dataset.variables['Min_LWP'][:].item()  # Assuming Min_LWP is a single value\n",
    "            # Print LWP units and other attributes\n",
    "            print(\"\\nLWP Attributes:\")\n",
    "            for attr_name in lwp_dataset.variables['LWP'].ncattrs():\n",
    "                print(f\"    {attr_name}: {getattr(lwp_dataset.variables['LWP'], attr_name)}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {lwp_file_path}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {lwp_file_path}: {e}\")\n",
    "\n",
    "    # Convert time variables to datetime\n",
    "    base_time = dt.datetime(2001, 1, 1, 0, 0, 0)\n",
    "    if time_iwv is not None:\n",
    "        times_iwv_converted = convert_time(base_time, time_iwv)\n",
    "    if time_lwp is not None:\n",
    "        times_lwp_converted = convert_time(base_time, time_lwp)\n",
    "\n",
    "    # Create dataframes\n",
    "    df_iwv = pd.DataFrame({'TIMESTAMP': times_iwv_converted, 'IWV': iwv_values})\n",
    "    df_lwp = pd.DataFrame({'TIMESTAMP': times_lwp_converted, 'LWP': lwp_values})\n",
    "    \n",
    "    # Add Min_LWP and calculate offset\n",
    "    if min_lwp is not None:\n",
    "        df_lwp['Min_LWP_MWR'] = min_lwp\n",
    "        df_lwp['Offset'] = df_lwp['Min_LWP_MWR'].apply(calculate_offset)\n",
    "        df_lwp['LWP_Corrected'] = df_lwp['LWP'] - df_lwp['Offset']\n",
    "    \n",
    "    # Merge dataframes on time\n",
    "    df_combined_iwv_lwp = pd.merge(df_iwv, df_lwp, on='TIMESTAMP', how='outer')\n",
    "\n",
    "    # Sort by time\n",
    "    df_combined_iwv_lwp.sort_values(by='TIMESTAMP', inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    df_combined_iwv_lwp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Set the 'TIMESTAMP' column as the index\n",
    "    df_combined_iwv_lwp.set_index('TIMESTAMP', inplace=True)\n",
    "\n",
    "    # Resample the data in 10-minute intervals and calculate the mean\n",
    "    df_combined_iwv_lwp_10min_avg = df_combined_iwv_lwp.resample('10T').mean()\n",
    "\n",
    "    # Reset the index to turn 'TIMESTAMP' back into a column\n",
    "    df_combined_iwv_lwp_10min_avg.reset_index(inplace=True)\n",
    "\n",
    "    # Define the path to save the CSV file\n",
    "    csv_file_path = os.path.join(day_folder_path, 'iwv_lwp_10min_avg.csv')\n",
    "\n",
    "    # Save the dataframe to a CSV file\n",
    "    df_combined_iwv_lwp_10min_avg.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    print(f\"10-minute average IWV and LWP data saved successfully to '{csv_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9073d6",
   "metadata": {},
   "source": [
    "### Temperature Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cabd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_mean_profile(profiles):\n",
    "    if len(profiles) == 0:\n",
    "        return []\n",
    "    profiles_array = np.array(profiles)\n",
    "    return np.mean(profiles_array, axis=0)\n",
    "\n",
    "def resample_and_average(df, interval='10T'):\n",
    "    resampled = df.resample(interval).agg({\n",
    "        'Altitude': 'first',  # Assuming altitude doesn't change frequently\n",
    "        'T_Profile': lambda x: compute_mean_profile(list(x))\n",
    "    })\n",
    "    return resampled\n",
    "\n",
    "#Edit before running!1\n",
    "# Define the base folder path\n",
    "base_folder_path = Path('path/to/Microwave_radiometer/month-folder') #<-- e.g., Path('/data/Microwave_radiometer/2024-06')\n",
    "\n",
    "# Iterate through each day's subfolder\n",
    "for day_folder in os.listdir(base_folder_path):\n",
    "    day_folder_path = os.path.join(base_folder_path, day_folder)\n",
    "    \n",
    "    if not os.path.isdir(day_folder_path):\n",
    "        continue  # Skip if not a directory\n",
    "    \n",
    "    # Find the .TPC.NC file for the current day\n",
    "    tpc_files = [f for f in os.listdir(day_folder_path) if f.lower().endswith('.tpc.nc') and not f.lower().endswith('.cmp.tpc.nc')]\n",
    "    \n",
    "    if not tpc_files:\n",
    "        print(f\"No valid .tpc.nc file found in {day_folder_path}\")\n",
    "        continue\n",
    "\n",
    "    tpc_file = tpc_files[0]  # Assuming there is only one file of interest\n",
    "    tpc_file_path = os.path.join(day_folder_path, tpc_file)\n",
    "\n",
    "    # Define variables to store data\n",
    "    time = None\n",
    "    altitude = None\n",
    "    T_profiles = None\n",
    "\n",
    "    # Open the NetCDF file\n",
    "    try:\n",
    "        with nc.Dataset(tpc_file_path, 'r') as tpc_dataset:\n",
    "            time = tpc_dataset.variables['time'][:]\n",
    "            altitude = tpc_dataset.variables['altitude'][:]\n",
    "            T_profiles = tpc_dataset.variables['T_prof'][:]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {tpc_file_path}\")\n",
    "        continue\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {tpc_file_path}: {e}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {tpc_file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check if variables are successfully extracted\n",
    "    if time is not None and altitude is not None and T_profiles is not None:\n",
    "        base_time = dt.datetime(2001, 1, 1, 0, 0, 0)\n",
    "        times_converted = [base_time + dt.timedelta(seconds=int(t)) for t in time]\n",
    "\n",
    "        profiles_data = {\n",
    "            'Time': times_converted,\n",
    "            'Altitude': [list(altitude)] * len(times_converted),\n",
    "            'T_Profile': list(T_profiles)\n",
    "        }\n",
    "        df_profiles = pd.DataFrame(profiles_data)\n",
    "\n",
    "        # Ensure 'Time' is a datetime type and set it as index\n",
    "        df_profiles['Time'] = pd.to_datetime(df_profiles['Time'])\n",
    "        df_profiles.set_index('Time', inplace=True)\n",
    "\n",
    "        # Compute the 10-minute averages\n",
    "        df_10min_avg = resample_and_average(df_profiles)\n",
    "\n",
    "        # Reset the index to make 'Time' a column again\n",
    "        df_10min_avg.reset_index(inplace=True)\n",
    "\n",
    "        # Save the 10-minute averaged DataFrame to a Parquet file\n",
    "        parquet_file_path = os.path.join(day_folder_path, 'vertical_temperature_profiles_10min_avg.parquet')\n",
    "        df_10min_avg.to_parquet(parquet_file_path, compression='gzip')\n",
    "        print(f\"10-minute averaged DataFrame saved to {parquet_file_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Data extraction failed for {tpc_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6f1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit before running!!\n",
    "#(Optional preview) Single parquet path: \n",
    "parquet_file_path = Path('/Microwave_radiometer/path/to/any/day/vertical_temperature_profiles_10min_avg.parquet')\n",
    "\n",
    "# Read the Parquet file\n",
    "try:\n",
    "    df = pd.read_parquet(parquet_file_path, engine='pyarrow')\n",
    "\n",
    "    # Print file information\n",
    "    print(f\"File: {parquet_file_path}\")\n",
    "    print(\"DataFrame contents:\")\n",
    "    print(df.head())  # Print the first 5 rows for inspection\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {parquet_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab696d83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Define variables to store data\n",
    "time = None\n",
    "altitude = None\n",
    "temperature_profiles = None\n",
    "\n",
    "\n",
    "\n",
    "# Find the file that ends with '.TPB.NC'\n",
    "tpb_file = next((file_name for file_name in datasets.keys() if file_name.upper().endswith('.TPB.NC')), None)\n",
    "\n",
    "if tpb_file:\n",
    "    tpb_dataset = datasets[tpb_file]\n",
    "\n",
    "    # Extract the variables (adjust variable names if necessary)\n",
    "    try:\n",
    "        time = tpb_dataset.variables['time'][:]\n",
    "        altitude = tpb_dataset.variables['altitude'][:]\n",
    "        temperature_profiles = tpb_dataset.variables['T_prof'][:]\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {tpb_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {tpb_file}: {e}\")\n",
    "\n",
    "# Plot the temperature and dry static energy profiles if variables are successfully extracted\n",
    "if time is not None and altitude is not None and temperature_profiles is not None:\n",
    "    # Convert time from seconds since 1.1.2001, 00:00:00 to datetime\n",
    "    base_time = dt.datetime(2001, 1, 1, 0, 0, 0)\n",
    "    times_converted = [base_time + dt.timedelta(seconds=int(t)) for t in time]\n",
    "\n",
    "    # Create a directory to save the plots if it doesn't exist\n",
    "    plots_folder = os.path.join(folder_path, 'temperature_profiles')\n",
    "    if not os.path.exists(plots_folder):\n",
    "        os.makedirs(plots_folder)\n",
    "\n",
    "    # Plot the temperature and dry static energy profiles\n",
    "    for i in range(len(times_converted)):\n",
    "        temperature_profile = temperature_profiles[i, :]\n",
    "        dry_static_energy = temperature_profile + (g * altitude) / C_p\n",
    "\n",
    "        # Plot figure\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(temperature_profile, altitude, label='Temperature')\n",
    "        plt.plot(dry_static_energy, altitude, linestyle='--', label='Dry Static Energy')\n",
    "        plt.xlabel('Temperature (K)')\n",
    "        plt.ylabel('Altitude (m)')\n",
    "        plt.title(f'Vertical Temperature and Dry Static Energy Profiles - {times_converted[i].strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "        plt.legend(loc='upper right', fontsize='small')\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save figure\n",
    "        save_path = os.path.join(plots_folder, f'temperature_profile_{i:04d}.png')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()  # Close figure after saving\n",
    "        \n",
    "        # Plot figure\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(temperature_profile, altitude, label='Temperature')\n",
    "        plt.plot(dry_static_energy, altitude, linestyle='--', label='Dry Static Energy')\n",
    "        plt.xlabel('Temperature (K)')\n",
    "        plt.ylabel('Altitude (m)')\n",
    "        plt.ylim(0,1000)\n",
    "        plt.title(f'Vertical Temperature and Dry Static Energy Profiles lowest 1km - {times_converted[i].strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "        plt.legend(loc='upper right', fontsize='small')\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save figure\n",
    "        save_path = os.path.join(plots_folder, f'temperature_profile_1km{i:04d}.png')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()  # Close figure after saving\n",
    "\n",
    "\n",
    "    print(f\"Plots saved successfully in '{plots_folder}' directory.\")\n",
    "\n",
    "else:\n",
    "    print(\"No file ending with '.TPB.NC' found or error accessing data.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f82ca",
   "metadata": {},
   "source": [
    "### RH, AH Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_profile(profiles):\n",
    "    if len(profiles) == 0:\n",
    "        return []\n",
    "    profiles_array = np.array(profiles)\n",
    "    return np.mean(profiles_array, axis=0)\n",
    "\n",
    "def resample_and_average(df, interval='10T'):\n",
    "    resampled = df.resample(interval).agg({\n",
    "        'Altitude': 'first',\n",
    "        'RH_Profile': lambda x: compute_mean_profile(list(x)),\n",
    "        'AH_Profile': lambda x: compute_mean_profile(list(x))\n",
    "    })\n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279da44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Edit before running!!\n",
    "# Define the main folder path\n",
    "main_folder_path = Path('/path/to/Microwave_radiometer/2024-06')\n",
    "\n",
    "# Iterate through each day's subfolder\n",
    "for day_folder in os.listdir(main_folder_path):\n",
    "    day_folder_path = os.path.join(main_folder_path, day_folder)\n",
    "    \n",
    "    if not os.path.isdir(day_folder_path):\n",
    "        continue  # Skip if not a directory\n",
    "    \n",
    "    # Find the .hpc.nc file for the current day\n",
    "    hpc_file = next((f for f in os.listdir(day_folder_path) if f.lower().endswith('.hpc.nc')), None)\n",
    "    if hpc_file is None:\n",
    "        print(f\"No .hpc.nc file found in {day_folder_path}\")\n",
    "        continue\n",
    "\n",
    "    hpc_file_path = os.path.join(day_folder_path, hpc_file)\n",
    "\n",
    "    # Define variables to store data\n",
    "    time = None\n",
    "    altitude = None\n",
    "    rh_profiles = None\n",
    "    ah_profiles = None\n",
    "\n",
    "    # Open the NetCDF file\n",
    "    try:\n",
    "        with nc.Dataset(hpc_file_path, 'r') as hpc_dataset:\n",
    "            time = hpc_dataset.variables['time'][:]\n",
    "            altitude = hpc_dataset.variables['altitude'][:]\n",
    "            rh_profiles = hpc_dataset.variables['RH_prof'][:]\n",
    "            ah_profiles = hpc_dataset.variables['AH_Prof'][:]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {hpc_file_path}\")\n",
    "        continue\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {hpc_file_path}: {e}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {hpc_file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check if variables are successfully extracted\n",
    "    if time is not None and altitude is not None and rh_profiles is not None and ah_profiles is not None:\n",
    "        base_time = dt.datetime(2001, 1, 1, 0, 0, 0)\n",
    "        times_converted = [base_time + dt.timedelta(seconds=int(t)) for t in time]\n",
    "\n",
    "        profiles_data = {\n",
    "            'Time': times_converted,\n",
    "            'Altitude': [list(altitude)] * len(times_converted),\n",
    "            'RH_Profile': list(rh_profiles),\n",
    "            'AH_Profile': list(ah_profiles)\n",
    "        }\n",
    "        df_profiles = pd.DataFrame(profiles_data)\n",
    "\n",
    "        # Ensure 'Time' is a datetime type and set it as index\n",
    "        df_profiles['Time'] = pd.to_datetime(df_profiles['Time'])\n",
    "        df_profiles.set_index('Time', inplace=True)\n",
    "\n",
    "        # Compute the 10-minute averages\n",
    "        df_10min_avg = resample_and_average(df_profiles)\n",
    "\n",
    "        # Reset the index to make 'Time' a column again\n",
    "        df_10min_avg.reset_index(inplace=True)\n",
    "\n",
    "        # Save the 10-minute averaged DataFrame to a Parquet file\n",
    "        parquet_file_path = os.path.join(day_folder_path, 'profiles_data_10min_avg.parquet')\n",
    "        df_10min_avg.to_parquet(parquet_file_path, compression='gzip')\n",
    "        print(f\"10-minute averaged DataFrame saved to {parquet_file_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Data extraction failed for {hpc_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Extract the first 10-minute profile\n",
    "first_10min_profile = df_10min_avg.iloc[0]\n",
    "\n",
    "# Extract altitude, RH_Profile, and AH_Profile\n",
    "altitudes = first_10min_profile['Altitude']\n",
    "rh_profile = first_10min_profile['RH_Profile']\n",
    "ah_profile = first_10min_profile['AH_Profile']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot RH_Profile\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rh_profile, altitudes, marker='o', linestyle='-')\n",
    "plt.xlabel('Relative Humidity (%)')\n",
    "plt.ylabel('Altitude (m)')\n",
    "plt.title('RH Profile for First 10-Minute Interval')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot AH_Profile\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(ah_profile, altitudes, marker='o', linestyle='-', color='orange')\n",
    "plt.xlabel('Absolute Humidity (g/m³)')\n",
    "plt.ylabel('Altitude (m)')\n",
    "plt.title('AH Profile for First 10-Minute Interval')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b403aea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Define variables to store data\n",
    "time = None\n",
    "altitude = None\n",
    "rh_profiles = None\n",
    "ah_profiles = None\n",
    "\n",
    "# Find the file that ends with '.HPC.NC'\n",
    "hpc_file = next((file_name for file_name in datasets.keys() if file_name.upper().endswith('.HPC.NC')), None)\n",
    "\n",
    "if hpc_file:\n",
    "    hpc_dataset = datasets[hpc_file]\n",
    "\n",
    "    # Extract the variables (adjust variable names if necessary)\n",
    "    try:\n",
    "        time = hpc_dataset.variables['time'][:]\n",
    "        altitude = hpc_dataset.variables['altitude'][:]\n",
    "        rh_profiles = hpc_dataset.variables['RH_prof'][:]\n",
    "        ah_profiles = hpc_dataset.variables['AH_Prof'][:]\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {hpc_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {hpc_file}: {e}\")\n",
    "\n",
    "# Plot the RH profiles if variables are successfully extracted\n",
    "if time is not None and altitude is not None and rh_profiles is not None and ah_profiles is not None:\n",
    "    # Convert time from seconds since 1.1.2001, 00:00:00 to datetime\n",
    "    base_time = dt.datetime(2001, 1, 1, 0, 0, 0)\n",
    "    times_converted = [base_time + dt.timedelta(seconds=int(t)) for t in time]\n",
    "\n",
    "    # Create frames for the entire day\n",
    "    filenames = []\n",
    "    for i, (t, rh_profile, ah_profile) in enumerate(zip(times_converted, rh_profiles, ah_profiles)):\n",
    "        plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "        plt.plot(rh_profile, altitude)\n",
    "        plt.xlabel('Relative Humidity (%)')\n",
    "        plt.ylabel('Altitude (m)')\n",
    "        plt.title(f'Relative Humidity Profiles - {t.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Add timestamp on top corner\n",
    "        plt.text(0.98, 0.98, t.strftime('%Y-%m-%d %H:%M:%S'), ha='right', va='top', transform=plt.gca().transAxes, fontsize=10, bbox=dict(facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Save the frame\n",
    "        frame_filename = os.path.join(folder_path, f'frame_{i:04d}.png')\n",
    "        plt.savefig(frame_filename)\n",
    "        filenames.append(frame_filename)\n",
    "        plt.close()\n",
    "\n",
    "    # Create GIF for the whole day\n",
    "    gif_filename = os.path.join(folder_path, 'RH_profiles_whole_day.gif')\n",
    "    with imageio.get_writer(gif_filename, mode='I', duration=0.5) as writer:\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    # Remove individual frames\n",
    "    for filename in filenames:\n",
    "        os.remove(filename)\n",
    "\n",
    "    print(\"GIF for the whole day created successfully.\")\n",
    "else:\n",
    "    print(\"No file ending with '.HPC.NC' found or error accessing data.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f24b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Continue from where the previous chunk left off\n",
    "\n",
    "# Plotting RH profiles for every hour\n",
    "if time is not None and altitude is not None and rh_profiles is not None and ah_profiles is not None:\n",
    "    # Convert time from seconds since 1.1.2001, 00:00:00 to datetime\n",
    "    base_time = dt.datetime(2001, 1, 1, 0, 0, 0)\n",
    "    times_converted = [base_time + dt.timedelta(seconds=int(t)) for t in time]\n",
    "\n",
    "    # Group profiles by hour\n",
    "    profiles_by_hour = {}\n",
    "    for t, rh_profile, ah_profile in zip(times_converted, rh_profiles, ah_profiles):\n",
    "        hour = t.hour\n",
    "        if hour not in profiles_by_hour:\n",
    "            profiles_by_hour[hour] = []\n",
    "        profiles_by_hour[hour].append((t, rh_profile, ah_profile))\n",
    "\n",
    "    # Plot profiles for every hour\n",
    "    for hour, profiles in profiles_by_hour.items():\n",
    "        plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "        for t, rh_profile, ah_profile in profiles:\n",
    "            plt.plot(rh_profile, altitude, label=t.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "        plt.xlabel('Relative Humidity (%)')\n",
    "        plt.ylabel('Altitude (m)')\n",
    "        plt.title(f'Relative Humidity Profiles - Hour {hour}')\n",
    "        #plt.legend(loc='upper right', fontsize='small')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot (optional)\n",
    "        plot_filename = os.path.join(folder_path, f'RH_profiles_hour_{hour}.png')\n",
    "        plt.savefig(plot_filename)\n",
    "        \n",
    "        # Show the plot (optional)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.close()\n",
    "9\n",
    "    print(\"Plots created successfully.\")\n",
    "else:\n",
    "    print(\"No file ending with '.HPC.NC' found or error accessing data.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the HPC data\n",
    "if time is not None and altitude is not None and rh_profiles is not None:\n",
    "    base_time = datetime(2001, 1, 1, 0, 0, 0)\n",
    "    times_hpc = convert_time(base_time, time)\n",
    "\n",
    "    # Create lists to store data for the dataframe\n",
    "    time_list_hpc = []\n",
    "    altitude_list_hpc = []\n",
    "    rh_list = []\n",
    "    \n",
    "    for i, t in enumerate(times_hpc):\n",
    "        for alt, rh in zip(altitude, rh_profiles[i, :]):\n",
    "            time_list_hpc.append(t)\n",
    "            altitude_list_hpc.append(alt)\n",
    "            rh_list.append(rh)\n",
    "    \n",
    "    # Create the dataframe\n",
    "    df_hpc = pd.DataFrame({\n",
    "        'Time': time_list_hpc,\n",
    "        'Altitude': altitude_list_hpc,\n",
    "        'Relative Humidity': rh_list\n",
    "    })\n",
    "else:\n",
    "    df_hpc = pd.DataFrame()\n",
    "    print(\"HPC data is incomplete or not loaded.\")\n",
    "    \n",
    "print(df_hpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4bb602",
   "metadata": {},
   "source": [
    "### Get qv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ce360",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_file = next((file_name for file_name in datasets.keys() if file_name.upper().endswith('.MET.NC')), None)\n",
    "\n",
    "\n",
    "if met_file in datasets:\n",
    "    met_dataset = datasets[met_file]\n",
    "\n",
    "    # Extract variables or perform operations here\n",
    "    # Example: printing metadata, dimensions, variables\n",
    "    print(f\"File: {met_file}\")\n",
    "    print(f\"File format: {met_dataset.file_format}\")\n",
    "\n",
    "    # Print dimensions\n",
    "    print(f\"Dimensions: {met_dataset.dimensions.keys()}\")\n",
    "\n",
    "    # Print variables\n",
    "    print(f\"Variables: {list(met_dataset.variables.keys())}\")\n",
    "\n",
    "    # Example: accessing a variable\n",
    "    if 'temperature' in met_dataset.variables:\n",
    "        temperature_data = met_dataset.variables['temperature'][:]\n",
    "        print(f\"Temperature data: {temperature_data}\")\n",
    "\n",
    "surf_p_values = None\n",
    "surf_t_values = None\n",
    "time_met = None\n",
    "\n",
    "# Check if the MET file exists in the dataset\n",
    "if met_file in datasets:\n",
    "    met_dataset = datasets[met_file]\n",
    "\n",
    "    # Extract Surf_P and Surf_T variables\n",
    "    try:\n",
    "        if 'Surf_P' in met_dataset.variables:\n",
    "            surf_p_values = met_dataset.variables['Surf_P'][:]\n",
    "        else:\n",
    "            print(f\"Variable 'Surf_P' not found in {met_file}.\")\n",
    "\n",
    "        if 'Surf_T' in met_dataset.variables:\n",
    "            surf_t_values = met_dataset.variables['Surf_T'][:]\n",
    "        else:\n",
    "            print(f\"Variable 'Surf_T' not found in {met_file}\")\n",
    "        \n",
    "        if 'time' in met_dataset.variables:\n",
    "            times = met_dataset.variables['time'][:]\n",
    "            base_time = dt.datetime(2001, 1, 1, 0, 0, 0)\n",
    "            time_met = [base_time + dt.timedelta(seconds=int(t)) for t in times]\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {met_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {met_file}: {e}\")\n",
    "\n",
    "else:\n",
    "    print(f\"File '{met_file}' not found in the dataset.\")\n",
    "\n",
    "if time_met is not None and surf_p_values is not None and surf_t_values is not None:\n",
    "    \n",
    "    # Create a dataframe with time, surface temperature, and surface pressure\n",
    "    df_met = pd.DataFrame({\n",
    "        'Time': time_met,\n",
    "        'Surface Temperature': surf_t_values,\n",
    "        'Surface Pressure': surf_p_values\n",
    "    })\n",
    "#print(df_met)\n",
    "\n",
    "# Plot surface temperature vs time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_met['Time'], df_met['Surface Temperature'], color='b')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Surface Temperature (K)')\n",
    "plt.title('Surface Temperature vs Time')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288b6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define variables to store data\n",
    "time_tpc = None\n",
    "altitude_tpc = None\n",
    "t_profs = None\n",
    "es_profiles = None\n",
    "\n",
    "# Find the file that ends with '.TPC.NC'\n",
    "tpc_file = next((file_name for file_name in datasets.keys() if file_name.upper().endswith('.TPC.NC')), None)\n",
    "\n",
    "if tpc_file:\n",
    "    tpc_dataset = datasets[tpc_file]\n",
    "\n",
    "    # Extract the variables (adjust variable names if necessary)\n",
    "    try:\n",
    "        time_tpc = tpc_dataset.variables['time'][:]\n",
    "        altitude_tpc = tpc_dataset.variables['altitude'][:]\n",
    "        t_profs = tpc_dataset.variables['T_prof'][:]\n",
    "        \n",
    "        \n",
    "        # Calculate es_profiles\n",
    "        es_profiles = np.array([calculate_saturation_vapor_pressure(T) for T in t_profs])\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable not found in {tpc_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data in {tpc_file}: {e}\")\n",
    "\n",
    "\n",
    "# Create a dataframe for the TPC data\n",
    "if time_tpc is not None and altitude_tpc is not None and t_profs is not None and es_profiles is not None:\n",
    "    base_time = datetime(2001, 1, 1, 0, 0, 0)\n",
    "    times_tpc = convert_time(base_time, time_tpc)\n",
    "\n",
    "    # Create lists to store data for the dataframe\n",
    "    time_list_tpc = []\n",
    "    altitude_list_tpc = []\n",
    "    t_profs_list = []\n",
    "    es_list = []\n",
    "    \n",
    "    for i, t in enumerate(times_tpc):\n",
    "        for alt, temp, es in zip(altitude_tpc, t_profs[i, :], es_profiles[i, :]):\n",
    "            time_list_tpc.append(t)\n",
    "            altitude_list_tpc.append(alt)\n",
    "            t_profs_list.append(temp)\n",
    "            es_list.append(es)\n",
    "    \n",
    "    # Create the dataframe\n",
    "    df_tpc = pd.DataFrame({\n",
    "        'Time': time_list_tpc,\n",
    "        'Altitude': altitude_list_tpc,\n",
    "        'Temperature': t_profs_list,\n",
    "        'Saturation Vapor Pressure': es_list\n",
    "    })\n",
    "else:\n",
    "    df_tpc = pd.DataFrame()\n",
    "    print(\"TPC data is incomplete or not loaded.\")\n",
    "print(df_tpc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b246db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "# Merge the two dataframes on the 'Time' column\n",
    "df_combined = pd.merge(df_hpc, df_tpc, on=['Time', 'Altitude'], how='inner')\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "print(\"Combined DataFrame:\")\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30994b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate vapor pressure and add it as a new column\n",
    "df_combined['ev'] = df_combined['Relative Humidity'] * df_combined['Saturation Vapor Pressure'] / 100\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "print(\"Combined DataFrame with Vapor Pressure:\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092fa40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Merge the met and tpc dataframes based on the Time column\n",
    "df_combined_pressure= pd.merge(df_met, df_combined, on='Time', how='inner')\n",
    "\n",
    "# Display the first few rows of the combined dataframe to ensure it looks correct\n",
    "print(df_combined_pressure.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db91618",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize an empty array to store pressure profile\n",
    "pressure_profile = np.zeros(df_combined_pressure.shape[0])\n",
    "\n",
    "# Calculate pressure profile using the formula\n",
    "for i in range(df_combined_pressure.shape[0]):\n",
    "    P_surf = df_combined_pressure['Surface Pressure'].iloc[i]\n",
    "    z = df_combined_pressure['Altitude'].iloc[i]\n",
    "    T = df_combined_pressure['Temperature'].iloc[i]\n",
    "    pressure_profile[i] = calculate_pressure(P_surf, z, T)\n",
    "\n",
    "# Add pressure profile to the dataframe\n",
    "df_combined_pressure['Pressure Profile'] = pressure_profile\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(df_combined_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170fe40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize an empty array to store specific humidity\n",
    "specific_humidity = np.zeros(df_combined_pressure.shape[0])\n",
    "\n",
    "# Calculate specific humidity using the formula\n",
    "for i in range(df_combined_pressure.shape[0]):\n",
    "    ev = df_combined_pressure['ev'].iloc[i]  # Vapor pressure in Pa\n",
    "    p = df_combined_pressure['Pressure Profile'].iloc[i]  # Atmospheric pressure in Pa\n",
    "    specific_humidity[i] = calculate_specific_humidity(ev, p)\n",
    "\n",
    "# Add specific humidity to the dataframe\n",
    "df_combined_pressure['qv'] = specific_humidity\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(df_combined_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a directory to save the plots if it doesn't exist\n",
    "plots_folder = os.path.join(folder_path, 'specific_humidity_profiles')\n",
    "if not os.path.exists(plots_folder):\n",
    "    os.makedirs(plots_folder)\n",
    "\n",
    "# Get unique times\n",
    "unique_times = df_combined_pressure['Time'].unique()\n",
    "\n",
    "# Plot specific humidity profiles for each unique time\n",
    "for i, time in enumerate(unique_times):\n",
    "    # Filter data for the current time\n",
    "    data_subset = df_combined_pressure[df_combined_pressure['Time'] == time]\n",
    "    \n",
    "    # Extract altitude and specific humidity\n",
    "    altitude = data_subset['Altitude']\n",
    "    specific_humidity = data_subset['qv']\n",
    "    \n",
    "    # Plot figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(specific_humidity, altitude)\n",
    "    plt.xlabel('Specific Humidity (g/kg)')\n",
    "    plt.ylabel('Altitude (m)')\n",
    "    plt.title(f'Specific Humidity Profile - {time}')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save figure\n",
    "    save_path = os.path.join(plots_folder, f'specific_humidity_profile_{i:04d}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()  # Close figure after saving\n",
    "\n",
    "print(f\"Plots saved successfully in '{plots_folder}' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d4f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Print dataset information\n",
    "print(\"NetCDF Dataset Information:\")\n",
    "print(dataset)\n",
    "\n",
    "# Print global attributes\n",
    "print(\"\\nGlobal Attributes:\")\n",
    "for attr_name in dataset.ncattrs():\n",
    "    print(f\"{attr_name}: {getattr(dataset, attr_name)}\")\n",
    "\n",
    "# Print dimensions\n",
    "print(\"\\nDimensions:\")\n",
    "for dim_name, dim in dataset.dimensions.items():\n",
    "    print(f\"{dim_name}: {len(dim)}\")\n",
    "\n",
    "# Print variables and their attributes\n",
    "print(\"\\nVariables:\")\n",
    "for var_name, var in dataset.variables.items():\n",
    "    print(f\"\\nVariable Name: {var_name}\")\n",
    "    print(f\"Dimensions: {var.dimensions}\")\n",
    "    print(f\"Shape: {var.shape}\")\n",
    "    print(f\"Data Type: {var.dtype}\")\n",
    "    for attr_name in var.ncattrs():\n",
    "        print(f\"    {attr_name}: {getattr(var, attr_name)}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c116c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling interval\n",
    "#long_name: rapid sampling multiplier (1 / 2 / 4)\n",
    "    #units: unitless\n",
    "    #Comment: Sampling interval: 1: 1 sec, 2: 0.5 sec , 4: 0.25 sec\n",
    "rs_factor = dataset.variables['RSFactor'][:]\n",
    "print(rs_factor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a281b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read variables\n",
    "#Variable Name: time\n",
    "#Dimensions: ('time',)\n",
    "#Shape: (17501,)\n",
    "#Data Type: int32\n",
    "  #  long_name: sample time\n",
    "  #  units: seconds since 1.1.2001, 00:00:00\n",
    "   # comment: time is UTC\n",
    "\n",
    "time = dataset.variables['time'][:]\n",
    "print(len(time))\n",
    "print(time)\n",
    "\n",
    "el_ang = dataset.variables['ElAng'][:]\n",
    "azi_ang = dataset.variables['AziAng'][:]\n",
    "lwp = dataset.variables['LWP'][:]\n",
    "rf = dataset.variables['RF'][:]\n",
    "min_lwp = dataset.variables['Min_LWP'][:]\n",
    "max_lwp = dataset.variables['Max_LWP'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time from seconds since 1.1.2001, 00:00:00 to datetime\n",
    "base_time = dt.datetime(2001, 1, 1, 0, 0, 0)\n",
    "time_converted = [base_time + dt.timedelta(seconds=int(t)) for t in time]\n",
    "\n",
    "# Plot Elevation Viewing Angle (ElAng) over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_converted, el_ang, label='Elevation Viewing Angle')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Elevation Viewing Angle (degrees)')\n",
    "plt.title('Elevation Viewing Angle Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Azimuth Viewing Angle (AziAng) over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_converted, azi_ang, label='Azimuth Viewing Angle')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Azimuth Viewing Angle (degrees)')\n",
    "plt.title('Azimuth Viewing Angle Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Liquid Water Path (LWP) over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_converted, lwp, label='Liquid Water Path')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Liquid Water Path (g/m^2)')\n",
    "plt.title('Liquid Water Path Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print min and max LWP\n",
    "print(f\"Minimum LWP: {min_lwp} g/m^2\")\n",
    "print(f\"Maximum LWP: {max_lwp} g/m^2\")\n",
    "## Plot Rain Flag (RF) over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.step(time_converted, rf, where='mid', label='Rain Flag', color='b')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Rain Flag (0 = No Rain, 1 = Raining)')\n",
    "plt.title('Rain Flag Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54b723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#edit before running!!\n",
    "# Open the NetCDF file\n",
    "file_path_2 = Path('/path/to/Microwave_radiometer/2024-05/2024-05-03/240503.TPC.NC')\n",
    "dataset2 = nc.Dataset(file_path_2, mode='r')\n",
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe3d5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print global attributes\n",
    "print(\"\\nGlobal Attributes:\")\n",
    "for attr_name in dataset2.ncattrs():\n",
    "    print(f\"{attr_name}: {getattr(dataset2, attr_name)}\")\n",
    "\n",
    "# Print dimensions\n",
    "print(\"\\nDimensions:\")\n",
    "for dim_name, dim in dataset2.dimensions.items():\n",
    "    print(f\"{dim_name}: {len(dim)}\")\n",
    "\n",
    "# Print variables and their attributes\n",
    "print(\"\\nVariables:\")\n",
    "for var_name, var in dataset2.variables.items():\n",
    "    print(f\"\\nVariable Name: {var_name}\")\n",
    "    print(f\"Dimensions: {var.dimensions}\")\n",
    "    print(f\"Shape: {var.shape}\")\n",
    "    print(f\"Data Type: {var.dtype}\")\n",
    "    for attr_name in var.ncattrs():\n",
    "        print(f\"    {attr_name}: {getattr(var, attr_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming dataset is the NetCDF dataset object\n",
    "# Access the temperature profile data\n",
    "T_prof_data = dataset2.variables['T_prof'][:]\n",
    "\n",
    "# Access time data\n",
    "time_data_2 = dataset2.variables['time'][:]\n",
    "start_time = datetime(2001, 1, 1, 0, 0, 0)\n",
    "time_utc = [start_time + timedelta(seconds=int(t)) for t in time_data_2]\n",
    "\n",
    "# Create a meshgrid for altitude and time\n",
    "altitude = dataset2.variables['altitude'][:]\n",
    "altitude_mesh, time_mesh = np.meshgrid(altitude, time_utc)\n",
    "\n",
    "# Plot the temperature profile\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(T_prof_data.T, extent=[np.min(time_utc), np.max(time_utc), np.min(altitude), np.max(altitude)], aspect='auto')\n",
    "plt.colorbar(label='Temperature (K)')\n",
    "plt.title('Temperature Profile')\n",
    "plt.xlabel('Time (UTC)')\n",
    "plt.ylabel('Altitude (m)')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
